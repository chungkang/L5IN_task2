# -*- coding: utf-8 -*-
"""pc2floorplan.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10DCbvKOETgW9lhLcbefpfxqxxrJxJcT6
"""

#############################################################################################################################################################################
# Point cloud to 2D GeoJSON or txt coordinate list.
# Author:  Vladeta Stojanovic (vladeta.stojanovic@hcu-hamburg.de)
# License: MIT
# Version: 110122_04
# 
# This tool takes in a point cloud of an indoor area, and generates first the initial boundary, then the secondary one featuring the room boundaries. 
# Both can then be combined or exported individually as a GeoJSON file or as a simple text file with wall coordinates. 
#
# Libraries:
#         (https://pypi.org/project/open3d/)
#         (https://pypi.org/project/alphashape/)
#         (https://pypi.org/project/rdp/)
#         (https://pypi.org/project/Shapely/)
#         (https://pypi.org/project/centerline/)
#
#############################################################################################################################################################################

#Todo:  - Add GeoJSON export
#       - Add simple txt wall lists export
#       - Add parameter input control

import copy
import os
import sys
import numpy as np
import cv2
import open3d as o3d
import matplotlib.pyplot as plt
from descartes import PolygonPatch
import shapely as sh
from shapely.geometry import Point, Polygon, LineString, MultiLineString
from shapely.ops import split
from shapely.ops import cascaded_union
import math
from itertools import groupby
from operator import itemgetter
from geojson import Feature, FeatureCollection, dump
import alphashape

if __name__ == "__main__":

  '''
  #STEP 1 - Procress point cloud and generate 2D PB and SBs
  #Load in point cloud
  #pcd = o3d.io.read_point_cloud("hcu_4g_high_res.ply")
  #print(pcd)

  #Sub sample - this is optional - up to 2 million is ok...
  #downpcd = pcd.voxel_down_sample(voxel_size=0.2) 
  #print(downpcd)

  #print("Running iterative RANSAC...")
  #room_planes = IterativeRansac(0.01, 3, 1000, pcd, 7, True)

  #Load biggest plane (aka the floorplan)
  print("Loading segmented floor plane...")
  floorplane = o3d.io.read_point_cloud("hcu_4g_high_res_pb.ply")
  print(floorplane)

  print("Loading segmented room boundaries...")
  room_boundaries = o3d.io.read_point_cloud("hcu_4g_high_res_sb.ply")
  print(room_boundaries)

  #Debug 3D viz for processed point cloud
  #print("Visualizing 3D Floorplane point cloud result...") 
  #o3d.visualization.draw_geometries([floorplane, room_boundaries])

  #Now generate 2D layers used for PB and SB detection
  
  #Transform point clouds into into 2D numpy array
  print("Converting floorplan (PB) to 2D numpy array...")
  pb_array = np.asarray(floorplane.points)
  pb_2D_array = np.empty([len(pb_array), 2])

  for i in range(len(pb_2D_array)):
      pb_2D_array[i, 0] = pb_array[i, 0]
      pb_2D_array[i, 1] = pb_array[i, 2]

  #print(pb_2D_array)
 
  print("Converting room boundaries (SB) to 2D numpy array...")
  sb_array = np.asarray(room_boundaries.points)
  sb_2D_array = np.empty([len(sb_array), 2])

  for j in range(len(sb_2D_array)):
      sb_2D_array[j, 0] = sb_array[j, 0]
      sb_2D_array[j, 1] = sb_array[j, 2]

  #print(sb_2D_array)

  #Save each PB PC layer as an image file that will be used for countour detection
  print("Generating 2D scatter plot of PB PC...")
  plt.scatter(pb_2D_array[:,0], pb_2D_array[:,1], s=2)
  plt.axis('off')
  plt.savefig('pb_pc.png', bbox_inches='tight', dpi=72 * 10)
  plt.show()

  print("Generating 2D scatter plot of SB PC...")
  plt.scatter(sb_2D_array[:,0], sb_2D_array[:,1], s=2)
  plt.axis('off')
  plt.savefig('sb_pc.png', bbox_inches='tight', dpi=72 * 10)
  plt.show()
  '''

  #Initial Hough transfomr test on SB
  print("Running contour detection on SB...")

  sb_contour_image = cv2.imread('sb_pc.png')

  #Blurring and threshold  
  print("Performing thresholding and morphological operations...")
  mask = np.zeros(sb_contour_image.shape, dtype=np.uint8)
  gray = cv2.cvtColor(sb_contour_image, cv2.COLOR_BGR2GRAY)
  blur = cv2.bilateralFilter(gray,9,75,75)
  thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]

  # Perform morpholgical operations
  kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (10,10))
  opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=1)
  close = cv2.morphologyEx(opening, cv2.MORPH_CLOSE, kernel, iterations=1)

  cv2.imwrite("1_sb_morphs.png", close)

  print("Running skeletonization filtering...")

  #Thining experiment: (https://stackoverflow.com/questions/58247563/middle-line-between-2-contour-lines-in-opencv-python)

  # read image and invert so blob is white on black background
  img = cv2.imread('1_sb_morphs.png',0)

  dist = cv2.distanceTransform(img, distanceType=cv2.DIST_L2, maskSize=3)

  cv2.imwrite("2_sb_morhps_dist_transform.png", dist)

  img = cv2.imread("2_sb_morhps_dist_transform.png")
  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

  thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]

  cv2.imwrite("3_sb_morhps_dist_transform_thresh.png", 255-thresh)

  img = cv2.imread("3_sb_morhps_dist_transform_thresh.png")
  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

  #Detect countors and filter using DP
  contours, hierarchy = cv2.findContours(gray, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE) #RETR_COMP gives us internal contours

  img_contours = np.zeros(sb_contour_image.shape)
  img_contours_dp = np.zeros(sb_contour_image.shape)

  for cnt in contours:
    #epsilon = 0.001*cv2.arcLength(cnt,True)
    #approx = cv2.approxPolyDP(cnt,epsilon,True)
    #cv2.drawContours(img_contours_dp, [approx], -1, (0, 0, 255), 1) 
    cv2.drawContours(img_contours, [cnt], -1, (0, 0, 255), 1) 

  print("Writting contouring results to files...") 
  cv2.imwrite("4_sb_contours.png", img_contours)
  print("Done!")

  #Flood fill and extract navigable area (https://stackoverflow.com/questions/60197665/opencv-how-to-use-floodfill-with-rgb-image)

  flood_fill = cv2.imread("4_sb_contours.png");
  seed = (1989, 1625)

  cv2.floodFill(flood_fill, None, seedPoint=seed, newVal=(0, 255, 0), loDiff=(5, 5, 5, 5), upDiff=(5, 5, 5, 5))

  seed = (1573, 2253)

  cv2.floodFill(flood_fill, None, seedPoint=seed, newVal=(0, 0, 255), loDiff=(5, 5, 5, 5), upDiff=(5, 5, 5, 5))

  seed = (0, 0)

  cv2.floodFill(flood_fill, None, seedPoint=seed, newVal=(255, 0, 0), loDiff=(5, 5, 5, 5), upDiff=(5, 5, 5, 5))

  print("Writting navigation polygon flood fill result to file...") 
  cv2.imwrite("5_sb_navigation_flood.png", flood_fill)

  #Load in flood-filled image, copy main floorplan component polygons with specific color
  green = [0,255,0]
  black = [0,0,0]
  white = [255, 255, 255]

  flood_poly = cv2.imread("5_sb_navigation_flood.png");
  Rmask = np.all(flood_poly == green,  axis=-1)
  flood_poly[~Rmask] = black

  cv2.imwrite('6_sb_navigation_polygon.png',flood_poly)

  flood_poly = cv2.imread("5_sb_navigation_flood.png");
  Rmask = np.all(flood_poly == black,  axis=-1)
  flood_poly[~Rmask] = white

  cv2.imwrite('7_sb_rooms_polygon.png',flood_poly)

  #TODO: Generate room boundary polygons - this becomes the "main" SB

  #Second pass contour filter with additional DP on navigation and room boundary polygons
  print("Running second pass contour filtering on SB hallway polygon, with additional DP filtering...")
  img = cv2.imread('6_sb_navigation_polygon.png')
  gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)
  contours_2, hierarchy_2 = cv2.findContours(gray, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

  img_contours_final = np.zeros(img.shape)
  img_contours_final_dp = np.zeros(img.shape) 
  
  navigation_polygon_points = []
  navigation_num_polys = 0

  for cnt in contours_2:
    epsilon = 0.001*cv2.arcLength(cnt,True)
    approx = cv2.approxPolyDP(cnt,epsilon,True)
    cv2.drawContours(img_contours_final_dp, [approx], -1, (0, 255, 0), 1) 
    cv2.drawContours(img_contours_final, [cnt], -1, (0, 255, 0), 1)

    #Get points to use construct Shapely file
    n = approx.ravel() 
    i = 0

    for j in n : 
      if(i % 2 == 0): 
        x = n[i] 
        y = n[i + 1] 
        navigation_polygon_points.append([navigation_num_polys, [x,y]])

      i = i + 1

    navigation_num_polys += 1

  print("Writting final contouring results to files...")
  cv2.imwrite("8_sb_navigation_contour.png", img_contours_final)
  cv2.imwrite("9_sb_navigation_contour_dp.png", img_contours_final_dp)
  print("Done!")

  print("Running second pass contour filtering on PB polygons, with additional DP filtering...")
  img = cv2.imread('7_sb_rooms_polygon.png')
  gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)
  contours_3, hierarchy_3 = cv2.findContours(gray, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)

  img_contours_final = np.zeros(img.shape)
  img_contours_final_dp = np.zeros(img.shape) 
  
  rooms_polygon_points = []
  rooms_num_polys = 0

  for cnt in contours_3:
    #DP Filtering
    epsilon = 0.005*cv2.arcLength(cnt,True)
    approx = cv2.approxPolyDP(cnt,epsilon,True)
    cv2.drawContours(img_contours_final_dp, [approx], -1, (0, 255, 0), 1) 
    cv2.drawContours(img_contours_final, [cnt], -1, (0, 255, 0), 1)

    #Compute convext hull instead of DP...
    #approx = cv2.convexHull(cnt, False)

    n = approx.ravel() 

    i = 0

    for j in n : 
      if(i % 2 == 0): 
        x = n[i] 
        y = n[i + 1] 
        rooms_polygon_points.append([rooms_num_polys, [x,y]])

      i = i + 1 

    rooms_num_polys += 1

  print("Writting final contouring results to files...")
  cv2.imwrite("10_sb_rooms_contour.png", img_contours_final)
  cv2.imwrite("11_sb_rooms_contour_dp.png", img_contours_final_dp)
  print("Done!")

  #STEP 2 - Convert navgiation polygon and rooms polygon to Shapely polgyons for analysis - the center point of each room polygon is also computed 
  print("Navigation polygon points - no DP fitlering")
  print("Number of polygons: ")
  print(navigation_num_polys)
  print("Number of points: ")
  print(len(navigation_polygon_points))
  
  print("Rooms polygon points - no DP fitlering")
  print("Number of polygons: ")
  print(rooms_num_polys)
  print("Number of points: ")
  print(len(rooms_polygon_points))
 
  #Generate main navigation polygon(s)
  shapely_points = []
  for poly in navigation_polygon_points:
    points = np.array(poly[1])
    points_list = points.tolist()
    shapely_points.append(Point(points_list))

  shapely_navigation_polygon = Polygon(shapely_points)
  print("Generated shapely navigation polygon...")

  #Generate room polygons
  print("Attempting to group rooms polygons by index key...")
  rooms_polygon_points_grouped = [list(g) for k,g in groupby(rooms_polygon_points, key=itemgetter(0))]

  #Generate each room polgyon
  polygon_points = []
  room_points = []
  alpha_room_points = []
  alpha_rooms = []

  for poly_group in rooms_polygon_points_grouped:
    #print("Polygon points:")
    for coords in poly_group:
      #print(coords[1])
      points = np.array(coords[1])

      #Used for alpha points correction
      alpha_tuple_points = tuple(points)
      alpha_room_points.append(alpha_tuple_points)

      #Used for normal non-alpha shape filtered points
      room_point_group = Point(points.tolist())
      polygon_points.append(room_point_group)
    
    room_points.append(polygon_points)
    polygon_points = []

    alpha_rooms.append(alpha_room_points)
    alpha_room_points = []

  #Alpha correction
  print("Running alpha point correction...")
  alpha_room_polygons = []
  for alpha_point_set in alpha_rooms:
    alpha = 0.01 * alphashape.optimizealpha(alpha_point_set) #0.95 is default
    hull = alphashape.alphashape(alpha_point_set, alpha)
    #hull_pts = hull.exterior.coords.xy
    alpha_room_polygons.append(hull)
  
  alpha_room_polygons.pop(0)
  fig = plt.figure() 
  ax = fig.gca() 
  for poly in alpha_room_polygons:
    ax.add_patch(PolygonPatch(poly, fc='#615f5f', ec='#bb00ff', alpha=0.5, zorder=1 ))
  ax.axis('scaled')
  plt.show()

  '''
  room_polygons = []
  for point_set in room_points:
    #print(point_set)
    room_polygon = Polygon(point_set)
    room_polygons.append(room_polygon)

  #Get rid of main boundary polygon
  room_polygons.pop(0)
  #alpha_rooms.pop(0)

  #Debug ouput for final procossed floorplan shape
  fig = plt.figure() 
  ax = fig.gca() 
  ax.add_patch(PolygonPatch(shapely_navigation_polygon, fc='#615f5f', ec='#bb00ff', alpha=0.5, zorder=1 ))
  for poly in room_polygons:
    ax.add_patch(PolygonPatch(poly, fc='#615f5f', ec='#bb00ff', alpha=0.5, zorder=1 ))
  ax.axis('scaled')
  plt.show()
  '''
  
  #Export GeoJSON - this works fine
  '''
  print ("Exporting merged GeoJSON...")
  floorplan_features = []
  floorplan_ref_feature_collection = None

  floorplan_features.append(Feature(geometry=shapely_navigation_polygon, properties={"info": "Single polygon PB shape"})) 
  for poly in room_polygons:
    floorplan_features.append(Feature(geometry=poly, properties={"info": "Single polygon SB shape"}))   

  print("Writting additional geo-referenced GeoJSON file...")
  floorplan_ref_feature_collection = FeatureCollection(floorplan_features)

  with open("floorplan_merged.geojson", 'w') as f:
    dump(floorplan_ref_feature_collection, f)

  print("Finished writting GeoJSON file...")
  '''

  #Export TXT points